\section{Bias}
\label{sec:ai}
\subsection{Was ist Kognitive Verzerrung?}

Zur Bestimmung systematischer fehlerhafter kognitiver Verzerrungen 
ist es zunächst notwendig, rationale Vergleichsstandards anhand 
prüfbarer Regeln zu entwickeln. Diese werden je nach Untersuchungsgegenstand 
anhand von normativen Modellen wie der mathematischen Wahrscheinlichkeitstheorie 
oder der Logik formuliert. Ein Vergleichsstandard kann aber auch ein 
faktisches Geschehen sein, das mit der Erinnerung an dasselbe verglichen 
wird (Gedächtnisillusionen). Systematische, also nicht nur individuelle 
und zufällige, Abweichungen von diesen Standards gelten dann als irrational 
oder falsch. Kognitive Verzerrung bezieht sich auf inhärente Verzerrungen oder 
Voreingenommenheiten, die im menschlichen Verhalten auftreten.\citep{Kognitive_Verzerrung}.

\subsection{Wie hängt das mit KI zusammen?}
Bias ist ein wichtiger Aspekt in Bezug auf Künstliche Intelligenz (KI), 
da es zu Vorurteilen und Diskriminierung führen kann. Wenn KI-Systeme nicht 
richtig trainiert sind, können sie unbewusste Vorurteile vorziehen und 
zu unfairen Entscheidungen führen. Es ist daher wichtig, sich mit dem Thema 
Bias in der KI-Ethik auseinanderzusetzen, um sicherzustellen, dass KI-Systeme 
gerecht und diskriminierungsfrei arbeiten, was aber nicht immer möglich ist, 
aufgrund der Anzahl genutzter Daten die das selbe aussagen. Wenn 90\% der Daten 
sagen das kleine Menschen dumm sind, wird die KI auch das sagen und diese Meinung 
vertreten und weiterüberlegund zusammenhänge finden. 

\subsection{Was sind Ursachen von Bias?}
Einige Ursachen von Bias sind die Beurteilung des Aussehens von Menschen, 
vorgefasste Meinungen, logische Fehlschlüsse und die Entscheidungsfindung basierend
auf Emotionen.
\begin{itemize}
    \item Geschlechtsbezogene Vorurteile
    \item Altersdisskriminierung
    \item Voreingenommenheit auf Grund des Namens
    \item Voreingenommenheit auf Grund der Attraktivität
    \item Voreingenommenheit durch Selbstüberschätzung
    \item Wahrnehmungsfehler
    \item Voreingenommenheit auf Grund des Aussehens
\end{itemize} \citep{Ursachen_Bias}

\subsection{Was sind die Folgen von Bias?}
Ein BEispiel hierführ wäre das Ereigniss aus 2019 in den USA.
In den Vereinigten Staaten wurde eine KI eingesetzt, um die 
Gesundheitsversorgung so effektiv wie möglich zu gestalten. 
Diese dient dazu, Patienten*innen mit speziellem Pflegebedarf zu 
identifizieren. 
Eine Studie, die im Oktober 2019 veröffentlicht wurde, weist jedoch darauf hin, 
dass Afroamerikaner*innen mit derselben Schwere der Erkrankung weniger 
häufig als Weiße für eine zusätzliche Pflege vorgeschlagen worden sind. 
Eine KI ohne Zweifel hätte in der Tat die doppelte Anzahl von Afroamerikaner*innen mit 
speziellem Pflegebedarf erfassen sollen. Wie ist eine KI, die eigentlich 
„farbenblind“ ist, zu diesen Resultaten gelangt?
Das Risiko der Patient*innen wurde durch den Algorithmus 
dieser KI als die voraussichtlichen Ausgaben für eine weitere Behandlung
festgelegt. Da der US-amerikanische Staat aufgrund verschiedener Faktoren weniger Geld für die 
Behandlung von Afroamerikaner*innen ausgibt, wurden die Ausgaben und damit auch das 
Risiko für Personen dieser ethnischen Gruppe als niedriger bewertet.